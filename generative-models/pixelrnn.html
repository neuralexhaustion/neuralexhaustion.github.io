<!DOCTYPE html>
<html lang="en">

<head>
    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
    <link href='https://fonts.googleapis.com/css?family=Source Sans Pro' rel='stylesheet'>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
    <link rel="stylesheet" href="deneme.css">


    <title>PixelRNN & PixelCNN</title>
</head>

<body>

    <!-- Navigation Bar -->
    <div>
        <div class="navbar">
            <ul>
                <li class='navr'><a class='nava' href="#">Contact</a></li>
                <li class='navr'><a class='nava' href="../about/index.html">About</a></li>
                <li class='navl'><a class='nava' href="../index.html">Home</a></li>
            </ul>
        </div>

        <!-- Blog -->
        <div class="blog">
            <hr>
            <hr>
            <h1 style="color:white;margin-bottom: 0px"> <span> üçÅ PixelRNN & PixelCNN</span> <span
                    style="float:right; color:#67AB9F;"><span style="color: rgb(246, 51, 102)">date</span>
                    17.09.2022</span></h1>

            <h2 style="padding-left: 70px; margin-top: 10px;"><span> Images as Sequence of Pixels</span> <span
                    style="float:right;color: #67AB9F; font-family: 'Source Sans Pro Semi-Bold'; font-size:2.75rem; font-weight: 700;"><span
                        style="color: rgb(246, 51, 102);">by</span style> Hidir Yesiltepe</span></h2>
            <br>
            <hr>
            <hr>
            <br>
            <figure>
                <div style="display: flex; justify-content:center">
                    <img src="assets_pixelrnn/cover.jpg" width="800px" alt="">
                </div>
                <div style="display: flex; justify-content:center">
                    <figcaption style="margin-top: 10px; font-size:14px; color:#757575;"> A Digital Fantasy Image
                        Generated by Midjourney</figcaption>
                </div>
            </figure>
            <h1>üçÅ Introduction </h1>
            <p>
                As an attempt to explore Autoregressive Models, with this blog post we are going to distill core
                ideas
                conveyed by <span style="color:rgb(246, 51, 102)">Pixel Recurrent Neural Network </span> paper that was
                published in 2016 by <span style="color: #0053D6;"> <b> DeepMind.</b></span> This almost classic paper
                demonstrates
                how an autoregression can be combined with existing components of deep neural networks in applications
                while preserving the
                backbone proposal of autoregressive models.
            </p>
            <br>
            <h1>üçÅ Task </h1>
            <p>Pixel Recurrent Neural Network is a generative model for images. Modelling the joint distribution of
                pixels is a challenging problem in unsupervised learning
                for several reasons.
                First of all, images are a type of extremely structured data, leading individiual pixels to become
                highly correlated with each other. To represent this complex distribution we look for a model that is
                <span style="color: rgb(246, 51, 102)">expressive</span>, <span
                    style="color: rgb(246, 51, 102)">scalable</span> but still <span
                    style="color: rgb(246, 51, 102)">tractable</span> which brings us to the second obstacle.
            </p>
            <br>
            <p>One
                natural solution to modeling joint distribution is representing it via conditional probability
                distributions by the chain rule of probability:</p>
            <p style="font-size: 1.8rem; font-family: 'KaTeX';">$$ P(x) = P(x_1, ..., x_N) = \prod_{i=1}^N P(x_i | x_1,
                ... x_{i-1})\tag{1}$$</p>
            <p>which translates seemingly unsupervised problem to supervised problem. Recall that the idea of
                autoregressive models is representing conditional probabilities with neural networks by ensuring:</p>
            <p style="font-size: 1.8rem; font-family: 'KaTeX';">$$ 0 \leq P(x_i | x_{< i}) \leq 1 \tag{2}$$</p>
                    <p style="font-size: 1.8rem; font-family: 'KaTeX';">$$ \sum_{\mathcal{X}} P(x_i | x_{<
                            i})=1\tag{3}$$</p>
                            <p>As far as images are concerned, <span style="color: rgb(246, 51, 102)">Equation
                                    [1]</span> states that in order to obtain probability of any pixel, we need to
                                condition our model to all the previous pixels. Below you see this conditioning in
                                action.
                            </p>
                            <br>
                            <br>
                            <div style="display: flex; justify-content: center;">
                                <div class="container"></div>
                                <script src="scripts/pixelrnn.js"></script>
                                <!-- <img src="assets_pixelrnn/arrow.png"  alt=""> -->
                                <span style="font-size: 10rem; margin-left: 5rem; color: #757575">&#8635; </span>
                            </div>
                            <br>

                            <figcaption style="text-align: center; margin-top: 10px; font-size:14px; color:#757575;">
                                Figure 1: Hover your mouse to see visually that each pixel value depends on all the
                                previous pixel
                                values.
                            </figcaption>
                            <br>
                            <p>Apart from generating new images, density estimator models can also be used for image
                                completion, image compression and deblurring tasks.</p>
                            <br>
                            <h1>üçÅ Contributions</h1>
                            <p>Pixel Recurrent Neural Network paper is quite reach in terms of contributions to
                                unsupervised learning. Although it seems there is only one model being proposed by just
                                looking at the title of the article, authors
                                described diverse variations of the same core idea. Below you see the complete set of
                                models brought to the literature.</p>
                            <br>
                            <figure>
                                <div style="display: flex; justify-content:center">
                                    <img src="assets_pixelrnn/model_tree.png" width="500px" alt="">
                                </div>
                                <br>
                                <div style="display: flex; justify-content:center">
                                    <figcaption style="margin-top: 10px; font-size:14px; color:#757575;"> Figure 2:
                                        Different Architectures Proposed by Pixel Recurrent Neural Network Paper
                                    </figcaption>
                                </div>
                                <br>
                                <p>PixelRNN uses a particular version of RNN architecture: <span
                                        style="color: rgb(246, 51, 102)">LSTM RNNs.</span> Based on how the dependencies
                                    between pixels are defined, how the receptive field of a particular pixel is
                                    structured and consequently how long range dependency is provided there are 3 main
                                    architectures proposed: <span style="color: rgb(246, 51, 102)">Row LSTM
                                        PixelRNN</span>, <span style="color: rgb(246, 51, 102)">Diagonal BiLSTM
                                        PixelRNN</span> and <span style="color: rgb(246, 51, 102)">Multi-scale
                                        PixelRNN.</span></p>
                                        <br>
                                <h1>üçÅ LSTM Equations</h1>
                                <p>We start our discussion on PixelRNN by reviewing the LSTM Equations and then we will
                                    see how these equations can be applied using <span style="color: rgb(246, 51, 102)">one-dimensional</span> convolutions.</p>
                                <br><br>



                                <!-- Blog End -->
        </div>
        <br><br>
</body>

</html>